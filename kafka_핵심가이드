kafka 핵심가이드

1장
-메트릭 : 시스템이나 앱의 성능이나 상태를 모니터링하기위한 측정 지표이며 측정치

-카프카 : 기존의 pub/sub이 복잡한 데이터 구조를 개선했지만, 전체적인 플랫폼의 역할은 힘들엇다함.. 그래서 카프카는 이를개선..(근데 rabbit도 플랫폼느낌이긴한데..)

-배치형식으로 보낼수있으.. 데이터를 압축해서 보낼수도있으니깐 더 많은데이터를 더 빠르게 보낼수도있음

-메세지 구조를 나타내는 스키마를 사용할수있다함.. 

-카프카에서의 스트림 : 프로듀서로부터 컨슈머로 이동되는 연속적인 데이터를 이야기함(이때는 파티션단위가 아닌 토픽단위!)

-브로커는 프로듀서로부터 메세지를 수신하고 오프셋지정하고 메세지를 디스크에 저장함.. 또한 컨슈머의 파티션 읽기 요청에 응답하고 디스크에 수록된 메세지를 전송.. 한 브로커가 수천개의 토픽과 수백만개의 메세지 처리가능

-브로커의 컨트롤러는 브로커중에 하나가 선정되며, 각 브로커에게 담당 파티션을 할당(브로커에게 파티션 리더 전달같음..)과 브로커들이 정상작동하는지 모니터링하는 역할을함

-토픽의 저장기간이있는데, 기간,용량으로 설정 가능하고, 압축도 가능하다.. 압축은 같은 키 가진것들중에 최신것만 보존된다..

-다중 클러스터가능함..

-데이터 파이프라인 개선에 매우 효과적


2장 카프카 설치와 구성
- 주키퍼는 카프카 클러스터(브로커들)에 관한 메타데이터(ex. 환경설정정보), 컨슈머클라이언트의 메타데이터를 저장히기위해 필요..

-num.recovery.threads.per.data.dir => 브로커의 시작과 종료시에만 사용되므로 병행 처리를 하도록 많은 수의 스레드를 설정하는것이좋음.. 기본적으로 로그 디렉토리당 하나임

-디스크에 보존하는 파티션 크기를 하루에 6GB미만으로 제한권장

-로그 파일이 log.segment.bytes 만큼 만들어져야 이제 쓰기를 멈추가 새로운 로그파일이 생성이되는데, 이때부터 log.retention.ms 로 지울시간을 산정한다.. 즉, log.retention.ms가 하루인데, 로그파일 만들어진게 10일 걸렸으면, 해당 로그파일이 삭제되려면 11일이 걸린다..
    -log.segment.bytes의 default값은 1GB

-카프카 컨슈머는 페이지 캐시를 사용하여 빠르게 처리한다.. 페에지 캐시로 사용되는 메모리가 많을수록 당연 더 빨라진다.. kafka는 java를 사용하기에, 힙메모리에 대한 할당을 적당양하고 나머지를 페이지캐시에 쓸수있도록 해주는것이좋다..
(초당 200메가바이트 전송률과 150,000개의 메세지를 처리하는 브로커일지라도 5GB 메모리면 충분하다함..)

-메모리와 디스크(용량뿐아니라 디스크처리관련..-ssd,hdd의 차이가 될수있겠지..) 가 제일 중요하지만 cpu또한 카프카에서 중요한데, 이는 압축된 메세지를 풀고 다시 압축해야하는 일이 있어서그렇다

-더티페이지..? 스왑..?
https://jhnyang.tistory.com/103


3장 프로듀서
- 바이트 시퀀스로 보낼수있는 서드파티 클라이언트가 있다네..
    *서드파티란? : 프로그래밍을 도와주는 플러그인이나 라이브러리 등을 만드는회사..
- ProducerRecord에 topic과 데이터를 넣어서 전달하면(partition과 key는 option..) 바이트배열로 직렬화(serializer가 custom한 객체들도 직렬화가능하도록해줌)를 하고, 파티셔너가 어떤 파티션으로 갈지를 결정해준다..(파티션을 지정안했을때에만 작동) 그리고 특정토픽과 파티션에 전송을 대기하고있는 배치들이 있고, 별도의 스레드가 배치로 모여진 데이터들을 발송함.. 
- key를 안써도 config에 key에 대한 직렬화를 어떻게할것인지 설정해주어야함
- send할때는 브로커에게 발생하는에러 또는 브로커로 메세지전송할때 발생하는 에러는 callback함수에서 받을수있지만, producer에서 에러나는부분들(직렬화실패, 버퍼가득찼을때, 메세지를 전송하는 스레드 중단 등)은 바로 예외처리가가능
- 메세지 전송할때 재시도 가능한 에러가있음.. 리더가 없거나 연결에러는 해당문제가 해결되어 다시시도되면 해결될수잇는부분이라 하여 재시도 구성가능하다.. 재시도 횟수가 소진되거나 에러가 해결안되었을때는 재시도관련 예외가 떨어진다
- 직렬처리기를 통해 객체 직렬화 또는 역직렬화가능.. arvo활용.. 스키마 레지스트리에 저장된것을 불러올수도있고, 스키마를 프로듀싱할때 직접 구성해서 보낼수도있음
- producing하면 key를 지정할수있는데, key를 가지고 hash알고리즘을 사용하여 특정 파티션에만 데이터를 pub 할수있도록한다.. 즉, 같은 key라면 같은 파티션! 그러나 파티션 증가하게되면 동일한 키가 추가되기 이전의 파티션으로 가지않을수있다.. 그래서 충분한 파티션 갯수를 지정해놓고 더이상 늘리지않는것이 좋다함.. key를쓴다면..
- producer는 메세지를 전송할때 지정된 batch size 크기가 찻는지 혹은 linger ms 에 설정한 시간이 지났는지를 보고 둘중에 어느하나만 만족하면 바로 발송을 시작한다

4장 컨슈머
- 컨슈머에서 poll은 중요한역할.. group coordinator찾기, 컨슈머그룹에 해당 컨슈머 추가, 컨슈머에게 할당된 파티션내역받기, group coordinator에게 하트비트전송..등.. 그래서 빠르게 poll을 다시불러줘야함..
- auto.offset.reset이 latest일때 프로듀서가 데이터를 신나게 쏘고있는 상황에서 파티션 하나가 새로 증가되었을때, 컨슈머가 새로이 생성된 파티션을 읽어갈때 일부 데이터가 누락될수있다..
    왜냐하면 파티션 새로 생기자마자 프로듀서는 그곳에다가 바로 데이터를 넣을것이고.. 만약 100개정도가 순식간에 들어왔을때 컨슈머가 새로이생긴 파티션으로부터 처음 Consume하게되면 100개 이후부터 가져간다.. 즉 100개는 유실..
- 컨슈머는 그룹의 일원이 되거나 스스로 파티션을 할당 받을수 있다.. 두가지 같이는 못함..
    -파티션을 할당받으면 rebalancing이 일어나지않고 partition도 자동으로 할당되지않기때문에 이에대한 로직처리를 해줘야함
- auto commit enabled 가 true이면 특정시간이 경과되었을때 poll함수 호출시 그 이전의 offset이 커밋
- auto commit enabled 가 false이면 commitSync(or async)를 호출해야하며, poll 함수 호출했을때의 offset이 커밋
- __consumer_offset
    -컨슈머가 커밋을 요청하면 카프카에서 __consumer_offset 토픽에 메세지를 쓴다
    -컨슈머 그룹이름, 토픽이름, 오프셋, COMMIT 시간, Expiration시간 등이 저장되어있다.
    kafka-console-consumer.sh --zookeeper 주키퍼주소/ --topic __consumer_offsets --formatter 'kafka.coordinator.GroupMetadataManager$OffsetsMessageFormatter' --max-message 1
-conusmer가 Kafka부터 데이터를 전송받는(kafka입장에서 보내는) 기준은 Fetch max wait ms 의 시간이 경과되거나 Fetch max bytes의 지정한 수가 넘겼을때임


5장 카프카 내부 매커니즘
- 브로커 중에 컨트롤러를 담당하는 브로커가있는데(카프카 클러스터에 처음 등록된 브로커로 선출..), 컨트롤러 브로커는 파티션의 리더선출을 담당함.. 컨트롤러 브로커는 반드시 하나이며 generation 번호가 새로이 생성될때마다 생겨서 이전 generation번호로 메세지가 발송되면 나머지 브로커들은 해당 메세지를 무시하게된다 
    - 또한 하나의 브로커가 죽거나 변경이 일어나면 해당 브로커의 파티션 리더들이 없어지므로 새로 선출하게되는데, 이러한 역할을 컨트롤러가 해준다...(해당파티션의 리플리카 리스트에서 그 다음순서의 브로커로 결정한다함..) 컨트롤러는 브로커들에게 새로운 파티션의 리더와 팔라워들에대한 정보를 전달해준다..

- 카프카 브로커는 클라이언트, 파티션 리플리카, 컨트롤러로부터 "파티션 리더"에게 전송되는 요청을 처리하는역할
    - processor 스레드가 요청을 받으면 요청 큐에 넣고, 응답큐에 데이터가 쌓이면 클라리언트에게 전송하는 일을 수행
    - 요청큐에서는 입출력 스레드가 데이터를 가져와서 처리하고 응답큐에 처리한것을 넣는다
    - 클라이언트가 파티션 리더가 없는 카프카 브로커에 요청(읽기 또는 쓰기)을 보내면 파티션 리더가 아니라는 에러를 뱉는다
        - 클라이언트는 메타데이터 요청을 통해서 토픽에 존재하는 파티션들, 각 파티션의 리플리카, 리플리카중 리더가 누구인지등에 대한 정보가 들어있다.. 이 메타데이터를 캐시에 보존하는데, 브로커나 파티션 관련 정보들이 변경될때 이에맞춰 교체함..
    - 읽기 요청은 쓰기 요청과 매우 유사..
        - 읽기요청또한 메타데이터를 받아서 토픽, 파티션, 오프셋 등을 포함해서 보내야할 브로커를 정하여 읽기 요청을 한다. 예를들면, Test 토픽 0파티션의 53오프셋, Test2 토픽 0 파티션의 29오프셋 전달해달라..
            -얼마만큼의 데이터를 받을것인지(max,min) 정할수있음.. 혹여나 min이 쌓이지않으면 시간을 정해서 해당시간이 지나면 그냥 보내달라고도 할수있다..(여기가 fetch max wait ms config..인듯)
                -Poll할때 데이터 달라는 요청을 하는데, fetch.min.byte가 채워지지않으면 fetch.max.wait.ms에 따라 요청의 응답을 보낸다. 
                예를들면 보낼데이터가 없더라도 fetch.max.wait.ms가 500(Default) 라면 데이터 보내달라는요청받은뒤(consumer가 poll함수호출) 0.5초 뒤에 응답받는다! 비록 fetch.min.byte가 1byte 여서 1byte를 채워야한다할지라도!!
            -중요한것은 컨슈머가 메세지를 받았다는것은 해당 파티션의 데이터는 동기화가끝났다는것을 의미! 카프카는 ISR 이 모두 데이터를 복제해야지만 안전한데이터라고 생각하기에 모든복제가끝난이후에 consumer에게 메세지를 보낸다

- 카프카는 데이터를 보존할때 압축을 사용하여 저장할수도있는데, 이 압축은 데이터의 용량을 줄이는 압축이아니라, 동일한 key값을 갖는 메세지들이 토픽에 여러번 저장되었을때 키를 중심으로 이전 것은 삭제하고 가장 최근 것만 남기는것을 말함..(즉 key값을 주지않으면 해당 내용은 필요없음)


6장 신뢰성 있는 데이터 전달 (실제 운용하기전에 체크사항들이 있으니 잘 숙지해놓을것!)
- 커밋된 메세지(ISR에서 모두 메세지를 저장)만 컨슈머는 읽을수있으며, 컨슈머가 이를 읽고 해당 오프셋을 커밋하면 커밋된 오프셋이된다..
- 컨슈머는 동기화가 이루어진 데이터를 읽게되는데, 동기화를 일정조건내에 이루어지지않아서 ISR 그룹내에서 박탈당하는놈은 컨슈머가 기다리지않는다. 즉, ISR그룹안에서 동기화가 끝난데이터만 컨슈머가 데이터르 읽는다.. 그러나 박탈당하게되면 이에따른 복제가 안되므로.. 조치가필요함!!
    - Out sync 된 replica(비동기 replica) 가 생기면 리더선출시 여러 고려사항들이 따른다.. 
        -만약 replica 3개중 리더를 제외한 나머지 팔로워 replica가 다 비동기 상태가되었다면 리더 리플리카가 죽었을때 리더 선출 정책에 따라 결정이 되는데 이때 가용성과 유실측면에서 리더 선출정책을 결정해야한다..
        -unclean.leader.election.enable을 true로 한다면 비동기되어있어도 리더로 선출하기때문에 비동기된 이후 못받았던 데이터가 유실된다.. 하지만 바로 사용가능하므로 가용성에서 좋다
        -unclean.leader.election.enable을 false로 놓는다면 죽은 리더가 다시 살아날때까지 기다린다.. 그렇게되면 신뢰성은 높아지지만 느리다..
        -이에 따라 최소 동기화 리플리카가 괜찮은 방법이라 생각됨.. acks=all로 하고 최소 동기화 리플리카를 지정해놓으면, 데이터를 Produce할때 아싸리 동기화시켜야할 replica가 지정한숫자보다 없으면 아예 데이터를 전송하지않고 에러를뱉는다.. 데이터 유실에 대한 위험도 없을것이고, 죽은 리더 그놈이 빨리 살아나서 문제없이 돌아가기만을 기다릴필요 혹은 데이터 살리기 위해 이런저런작업을 할 필요도없다.. 
- kafka는 at least once는 지원되나, exactly once는 지원되지않는다. 
    *at least once : 적어도 한번은 간다! 중복가능하다..
    *exactly once : 정확히 한번만!!
    -이를 해결하기위해 고유키를 지원하는 외부시스템에 식별 데이터를 쓰는것! 키-값데이터스토어, 관계형DB, 엘라스틱서치 를 사용할수있음!(카프라 레코드에 고유한 키를 넣는걸 많이쓴다함..)
- 아파치 카프카 소스 repository에는 많은 테스트 세트가있다! 이를 활용해서 카프카의 여러 장애상황들을 어떻게 핸들링할지 알아볼것!! (p146참고..)


7장 데이터 파이프라인 구축하기
- 카프카 커넥트는 외부 시스템과의 데이터 통합에 필요한 API를 제공하여, 데이터 전달 파이프라인을 쉽게 구축할수잇다..
- 데이터 파이프라인을 구축하기위해서는 데이터의 소스와 싱크는 스키마(여기서 스키마는 데이터 구조.;.)를 갖는데, 이에 대한 소스와 싱크의 호환성과 소스 또는 싱크의 동작들까지도 지원이 가능하여야하는점을 염두해서 만들어져야한다..
*소스 : 데이터를 발행하는쪽
**싱크 : 데이터를 받는쪽
- 데이터 파이프라인 구축에는 ETL, ELT두가지가 있다
   - ETL(Extract Transform Load) : 데이터를 추출해서 변환하고 적재하는것인데, 데이터에대한 변환을 데이터파이프라인안에서 하게된다.. 이는 데이터를 받는 대상이 데이터활용하는데에 있어서 특정 스펙에만 맞추게 되므로 유연성이 떨어지게된다..(데이터파이프라인에서 특정데이터만 가지고 싱크에게 전달하게되므로.. 다른 싱크들이 나타나면 딱 정의된 특정데이터만 가져갈수밖에없음)
   - ELT(Extract Load Transform) : 데이터를 추출해서 적재하고 변환은 싱크쪽에서 하는것.. 원시데이터를 그대로 전달해주니깐 싱크쪽에서 데이터를 변환해야하기에 cpu에는 약간의 부담이 될수있음.. 그러나 싱크쪽에서 원시데이터를 받게되므로 특정 데이터를 추가하거나 제외하거나 매우 유연하게 핸들링가능
- 카프카는 암호화된 데이터의 네트워크 전송을 허용하며, SASL(simple authentication and security layer) 인증을 지원.. 인증되지않은 타겟으로 데이터전달안함,, 시스템 접근을 추적관리하기위해 audit로그가 있다함.. 추가로 약간의 코드를 더하면 각 토픽의 데이터가 어디서부터왔고 누가 그것을 수정했는지도 알슁ㅆ음
- 데이터 파이프라인을 수행한다면(애플리케이션이 될수있음..) 앤드포인트와 강력하게 결합되어있으면 안된다.. 유지보수와 모니터링에 많은 비용이듬..
- 메타데이터를 관리할수있어야.. 스키마와 같은것들이 진화될수있을텐데, 그때 기존의 스키마를 사용하는것을 호환하지않게되면 기존 데이터파이프라인을 사용하고있는곳이 하나라도 있다면 장애가 일어날것.. 즉, 스키마진화를 지원할수있어야한다..
- 데이터 파이프라인은 최대한 원시데이터를 많이 보존해주는게 유연성 및 유지보수면에서 좋음..
- 카프카 커넥트 vs 프로듀서/컨슈머
   -파싱필요한데, 커넥트에서 지원해주는 파싱이면 커넥트 걍쓰면댐.. 안전하니깐.. (ETL의 예외처리들을 이미 다 해놓은 커넥트가좋다..!)
   ???? 커넥트쓸때 만약 리벨런싱일어날때 중복발송을 줄이기위한 처리와같은 세부적인 내용들은 어떻게봐야하나..?
      =>p153에서 exactly once를 좀더 쉽게 구현할수있다함..
- 카프카 커넥트
   - 직접해보자...p159.. rest api 호출만으로 모든 설정이 셋팅되고 카프카를 통해서 데이터를 전달할수잇다.. 예를들어 mysql에 데이터를 insert하면 해당 데이터를 엘라스틱서치로 전달한다.. api로 셋팅만 제대로한다면!
   - 대충 정리하자면 작업프로세스라는 컨테이너가 커넥터와 테스크를 실행해준다.. 
      -작업프로세스는 rest api, 구성관리, 신뢰성, 높은 가용성, 확장성, 부하분산등의 모든 작업을 처리하는 책임이 있다.
      -커넥터는 연결시켜야할 대상의 데이터들을 받아주거나(소스) 전달해주는(싱크) 역할을한다..
      -소스입장에서 커넥터가 데이터를 받아주었을때 카프카 브로커에 데이터를 pub하는것이 작업프로세스인데, pub할때 Arvo객체, json객체, 문자열중 하나로 저장이되는데 이 변환의 역할을 해주는것인 컨버터이다
      -반대로 싱크에서는 카프카 브로커에서 작업프로세스가 consume해오면 컨버터가 커넥터에게 전달될수있도록 레코드를 변환시켜준다..


8장 크로스 클러스터 데이터 미러링
-어렵다.. 실무적인부분을 많이 접해야하고 규모가 큰곳에서는 사용할수밖에없는 프로세스이니.. 실력을 쌓고 꼭 다시 볼것!


9장 카프카 관리하기
-명령행 인터페이스(command-line interface) cli를 제공해주는데, 주키퍼에 직접 접근하여사용하는것이기에, 브로커의 버전과 일치하는게 좋고.. 제일좋은것은 그냥 배포한곳의 cli를 사용하는것이 가장안전
-kafka-topics.sh : 토픽생성,변경,삭제,정보조회 등 토픽작업을 쉽게할수있음
    -describe: 하나 이상의 토픽에 대한 상세정보를 볼수있음,, 추가적으로 옵션을 더해주면 클러스터 문제를 진단하는데도 유용하게 사용가능
        1) "--topics-withoverrides" : 기본설정값에서 변경된 토픽들만 나타남
        2) "--underreplicated-partitions" : 리더 리플리카는 있는데, 하나 이상의 리플리카가 동기화되지않는 모든 파티션을 보여줌
        3) "--unavailable-partitions" : 리더 리플리카가 없는 모든 파티션을 보여줌..
         => 2),3) 의 경우에는 오프라인 상태라서 프로듀서나 컨슈머 클라이언트가 사용할수없으므로 심각한상황!!
-로그 세그먼트 내용볼수있음.. 
    -kafka-run-class.sh kafka.tools.DumpLogSegments --files xxxx.log --print-data-log

-Preferred Replica Election 
    -처음 파티션의 리더가 된놈을 Preferred replica 라고 하는데, 해당 리더가 있는 브로커가 죽게되어 다른 브로커에 리더가 새로 선출이되었고 + 새로운 메세지가 유입된 후 + 기존에 죽었던 브로커 다시 살아나게된다면
        살아난 브로커는 out sync replica 가 되어 리더의 역할을 가질수없게된다.. 이때 "Preferred Replica Election" 을 하게되면 OSR이었던 리더 파티션이 sync를 맞추고 리더로 복구가된다..
    -이것을 하는 이유는, 파티션의 리더였던 브로커가 무너지게되면서 새로운 리더들이 생겼을때 특정 브로커로 리더들이 몰리게될수있다.. 이렇게 되면 성능에 부하가 올수있기때문에 다시 preferred replica로 이전상태로 복구하여 이전과같이 파티션을 고루분배하게 해주는게좋다


10장 카프카 모니터링
-카프카 모니터링을 하려면 kafka뿐 아니라 연동된 kafak client앱 들을 확인 할수있는 외부 메트릭 또한 모니터링이 필요하다!
-메트릭 : 성능이나 상태를 모니터링 하기위한 지표
    -내부메트릭 : JMX와 같은 인터페이스로 제공해주는 메트릭
    -외부메트릭 : 요청의 전체 소요시간이나 특정 요청의 타입의 사용가능 여부등과 같은 것.. 즉, 요청에 관련된 메트릭이라보면됨.. producer가 데이터를 전달했는데 잘안됐다면 브로커 문제가있다는것을 알려줄것이고, Producer가 데이터를 입력하고자하는 요청을 보냇는데 이에대한 처리시간도 알려줄수있음
    -메트릭에 대한 정보가 너무 많기때문에 모니터링에서 메트릭의 모든 알람을 달아놓을수는없다..! 혼란만 야기.. => 중대한 문제관련해서만 소수의 알람을 설정하고 이를 발견했을때 세부적으로 찾아들어가게하는것이 좋다함..

-OS의 문제로 카프카 클러스 내부에서 복제하는데 문제가있다면, 실제적으로 카프카의 client를 사용하고잇는 app에 모든 문제가 생긴것과 같다.. 왜냐하면 클러스터 내부에서 복제하는 로직은 카프카 클라이언트를 사용하기 때문이다
-현재 파티션 리더가 아예 없는것을 알수있음.. 
    => kafka.controller:type=KafkaController, name=OfflinePartitionsCount

-모니터링시 필요한 메트릭 
    -카프카 브로커 매트릭
        -미복제파티션(Under Replicated Partitions) : 복제되지 않은 파티션 갯수 (팔로워 리플리카 브로커들이 복제하지 못ㅅ하고 있는 파티션 총 갯수)
            -지속 유지되면 브로커 뒤진것,, 이런 현상이 나타났을때에 가장먼저 "선호 리플리카 선출"을 진행해보는게 우선!! (브로커 다시 살아났을수도 잇으니까..! 즉, 브로커는 살아났는데 파티션리더가 기존껄로 옮겨가지못한거지..)
        -ActiveContorllerCount : 실행되고있는 컨트롤러 갯수
            -1이면 해당 브로커가 controller
            -모두 0이면 문제있음.. 1이 두개이상이어도 문제있음..
        -RequestHandlerAvgIdlePercent : 요청핸들러에 대해 사용중이지 않은 시간에 대한 백분율
            -카프카는 모든 클라이언트의 요청을 처리하기위해 두개의 스레드 풀을 사용 ( 네트워크 스레드풀 / 요청핸들러 스래드풀)
                -네트워크스레드풀 : 클라에서 전달받은 데이터를 읽고 쓰는역할.. 크게 중요치않음..
                -요청핸들러스레드풀 : 클라요청에따라 디스크에 메세지를 쓰고 읽는 서비스.. 이게 매우중요! 이것에 대한지표임
            -20%미만이면 잠재적문제.. 10%미만이면 성능문제진행중!
        -BrokerTopcMetrics-ByteInPerSec: 데이터 유입
            -클러스터 확장해야할때의 타이밍을 아수있음.. 데이터 유입이 적을때 해야하니께
            -브로커들이 균등하게 메세지를 받고있는지를 확인가능,, 만일 아니면 파티션 리밸런싱 필요
            -count를 통해서 전체 바이트 알수있음
        -BrokerTopcMetrics-ByteOutPerSec: 데이터 out
            -컨슈머가 메세지 읽는 속도를 보여준다 할수있음
            -그러나 팔로워 리플리카에서 데이터 Consume해가는것도 포함됨..
        -ReplicaManager-LeaderCount : 브로커가 현재 리더인 파티션의 수를 보여줌
            -백분율로 사용하면좋음
        sum(kafka_server_ReplicaManager_Value{name="LeaderCount"}) by(instance) / sum(kafka_server_ReplicaManager_Value{name="PartitionCount"}) by(instance) 
        -KafkaController OfflinePartitionsCount
            -offline 파티션의 총계 (클러스터에서 현재리더가 없는 파티션의 갯수)
            -해당 파티션의리더, 팔로워인 모든 브로커 다운되었을때...
            -동기화 리플리카 없고(리더없고&리더될수있는놈들도없고) unclean.leader.election=fale 일때..
        -토픽과 파티션 매트릭 (자세하게 확인해야할때 사용하면됨)
            -토픽 메트릭 : 토픽별 바이트입력, 바이트 출력, 읽기실패요청수, 쓰기실패요청수, 입력메세지수, 전체읽기 요청수, 전체쓰기요청수 알수있음 (P265참고)
            -파티션 메트릭 : 파티션별 크기, 로그 세그먼트 개수, 로그 끝 오프셋, 로그시작오프셋 알수있음(p265참고)
                -해당 파티션의 디스크 저장된 용량 알수있음.. 해당 토픽의 파티션들을 합치면 디스크에 토픽의 기록된 양(byte) 알수있음
        -JVM
            -가비지 컬렉션 얼마나 걸리는지 모니터링필요!(걸리는 시간에 대한 Metric이 있음)
        -OS
            -CPU사용
            -메모리사용
            -디스크사용
            -디스크입출력
            -네트워크사용
        -로거
            -로그레벨에 따라 남기는것들이 있는데, 디시크에 부담이 될만큼 너무 많이 남기면 좋지 않으므로 필요한 로그만 적정 level로 맞춰서 남길것!(P269참조)

    -클라이언트 모니터링
        -producer
            -Record-error-rate 항상 0 이어야함.. 만약 0보다 크면 메세지 전송시도하다가 삭제된게 있는것!
        -consuemr
            -fetchManager
            -컨슈머조정자
                -sync-time-avg : 리밸런싱 일어날때 조정되는 시간
                -consume-latency-avg : 커밋이 처리되는 평균시간
            -lag 모니터링 : burrow 사용해볼것!!@
                


   