Kafka

카프카 설정 정리 & 개념등등 많은것들이 정리..아주좋음 : 1) https://12bme.tistory.com/529?category=737765
                                            2) https://www.popit.kr/author/peter5236
producer : 프로듀서의 주요 기능은 각각의 메시지를 토픽 파티션에 매핑하고 파티션의 리더에 요청을 보내는 것이다. 
    리더 <-> 팔로워 (복제된애)

개발 입장에서도 이전에는 데이터 스토어 백엔드 관리와 백엔드에 따른 포맷, 별도의 앱개발을 해야 했는데 이젠 카프카에만 데이터를 전달하면 나머지는 필요한 곳 또는 다른 서비스들이 각자 가져갈 수 있어서 자신들 본연의 업무에만 집중할 수 있게 되었다.


카프카 데이터 모델
카프카가 고성능, 고가용성 메시징 애플리케이션으로 발전한 데는 토픽과 파티션이라는 데이터 모델의 역할이 컸다. 토픽은 메시지를 받을 수 있도록 논리적으로 묶은 개념이고, 파티션은 토픽을 구성하는 데이터 저장소로서 수평 확장이 가능한 단위이다.
 
1) 토픽의 이해
카프카 클러스터는 토픽이라 불리는 곳에 데이터를 저장한다. 토픽 이름은 249자 미만으로 영문, 숫자, '.', '_', '-'를 조합하여 자유롭게 만들 수 있다. 현재 운영하는 카프카 클러스터 또는 앞으로 운영하게 될 카프카 클러스터를 하나의 서비스에 독립적으로 사용하는 것이 아니라 여러 서비스에서 공통으로 사용하게 된다면, 각자 형식에 맞추어 토픽 이름을 구분해주는 것이 좋다.
 
2) 파티션의 이해
카프카에서 파티션이란 토픽을 분할한 것이다. 메시징 큐 시스템의 경우, 메시지의 순서가 보장되어야 해서 이전 메시지 처리가 완료된 후 다음 메시지를 처리하게 된다. 결국 카프카에서 효율적인 메시지 전송과 속도를 높이려면 토픽의 파티션 수를 늘려줘야 한다. 빠른 전송을 위해서 토픽의 파티션을 늘려주는게 좋으며 그 수만큼 프로듀서 수도 늘려야 제대로 된 효과를 볼 수 있다. (초당 받을 수 있는 메시지의 양 고려해서, 파티션 수 조정한다.)
적절한 파티션 수를 측정하기 어려운 경우에는 일단 적은 수의 파티션으로 운영해보고, 프로듀서 또는 컨슈머에서 병목현상이 발생하게 될 때 조금씩 파티션 수와 프로듀서 또는 컨슈머를 늘려가는 방법으로 적정 파티션 수를 할당할 수 있다.
 
카프카에서는 브로커당 약 2,000개 정도의 최대 파티션 수를 권장하고 있기 때문에 과도한 파티션 수를 적용하기보다는 목표 처리량에 맞게 적절한 파티션 수로 유지, 운영하는 것이 좋다.
 
3) 오프셋과 메시지 순서
카프카에서는 각 파티션마다 메시지가 저장되는 위치를 오프셋이라고 부르고, 오프셋은 파티션 내에서 유일하고 순차적으로 증가하는 숫자(64비트 정수) 형태로 되어있다.
오프셋은 하나의 파티션 내에서만 유일한 숫자이다. 토픽 기준으로 오프셋이 0인 것을 찾아보면 전부 3개가 존재하게 된다. 하지만 0번 파티션 기준으로 보면 오프셋 0은 유일한 값이다. 카프카에서는 이 오프셋을 이용해 메시지의 순서를 보장한다. 만약 컨슈머가 파티션 0에서 데이터를 가져간다고 가정하면, 오프셋 0, 1, 2, 3, 4, 5 순서대로만 가져갈 수 있다. 절대로 오프셋 순서가 바뀐 상태로는 가져갈 수 없다.


출처: https://12bme.tistory.com/532?category=737765 [길은 가면, 뒤에 있다.]

topic, replication, irs 설명 : https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-topic-replication/



replication : leader 와 follower로 구분이된다.. 오프셋같은것들이 모두 동기화되어있다.. 
-leader : leader는 읽고 쓰는 역할을 한다.. 그리고 follower를 지속적으로 체크해서 leader가 될수 없는놈(나로부터 데이터 못가져가는) 은 ISR에서 퇴출시킨다..
-follower : leader에게 데이터가져와서 복제함
*ISR(In Sync Replica) : 같은 topic으로 복제된 그룹 정도로 이해하면될듯함.. replication group..
자세하고 그림있는 설명 : https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-topic-replication/

용어정리 
-broker: 카프카 설치된 서버
-partition : topic에 들어온 데이터를 저장하는 곳.. 토픽을 몇개로 나눌지를 정의한다고 보면됨.. 즉, 파티션이 많으면 토픽에 들어오는 데이터가 분산되어서 들어감
-replica : 복제하는수
-topic : topic을 가지고 pub/sub이 이루어짐,, 저장되는 데이터는 topic을 기준으로!
-consumer group : 하나의 토픽에 여러 컨슈머 그룹이 데이터를 가져올수있다.. 컨슈머그룹의 하위인 컨슈머는 파티션과 1:1로 혹은 N(파티션갯수):1로 붙게되는데, 당연히 병렬로 처리할거면 컨슈머갯수를 파티션갯수만큼 맞춰서 1:1이 좋다.. 그러나 파티션이 많다는것은 속도는 빠르겠지만 순서는 보장안한다..
***Consumer Group란? 컨슈머 인스턴스들을 대표하는 그룹 Consumer Instance란? 하나의 프로세스 또는 하나의 서버라고 할 수 있습니다. 여기에서는 이해를 돕기 위해서 하나의 서버로 설명하겠습니다. Offset란? 파티션안에 데이터 위치를 유니크한 숫자로 표시한 것을 offset이라 부르고, 컨슈머는 자신이 어디까지 데이터를 가져갔는지 offset을 이용해서 관리를 합니다.
-lag : consumer에 저장된 offset과 producer를 통해 topic(의 partition)에 들어온 offset total의 차이..
***주의할점 : 앱구동시 프로그램 내부적으로는 ack를 manual로 놓았을때 acknowlegement를 호출하지 않은상태에서 onMessage 함수가 끝나면(에러나도 동일) 전달받은 메세지는 다시 받지않는다.. seek을 통해 특정 offset으로 변경하지않는이상.. 그러나, acknowlegement를 호출하지않았으므로 consumer의 offset이 kafka에 저장되지 않았으므로 재기동시에 ack가 안된 offset 부터 데이터들을 쭉 읽어온다..  


-broker에는 하나의 파티션이 들어가게되고, 해당 파티션이 다른 브로커에 replication 된다.. 그때 leader와 follower가 나눠져서 leader만 데이터를 읽고 쓰게 된다. 그리고 이런 파티션이 하나의 브로커에 여러개가 생길수있다.. leader는 될수도 아닐수도~
broker1 - partition1(leader), partition2(follower)
broker2 - partition1(follower), partition2(leader)
broker3 - partition1(follower), partition2(follower)

-consumer가 poll과 commit할때 heart beat를 그룹코디네이터한테 보내어, consumer가 살아있음을 알려주게되는데, poll이나 commit을 통해 하트비트를 안보내주게되면 그룹코디네이터가 해당 consumer가 죽은걸로 판단하여 rebalancing이 일어나게 된다

주키퍼
-분산 애플리케이션을 관리하기위한 애플리케이션..
-즉, 여러 서버에 카프카를 설치하게되면 이를 통합적으로 관리할 코디네이션 앱이 필요한데, 주키퍼가 그 역할을 담당한다.
-각 애플리키션의 정보를 중앙에 집중하고 구성관리, 그룹관리 네이밍, 동기화 등의 서비스를 제공한다.

로그
-카프카에 저장된 메세지를 읽기위해서는 offset정보를 알아야하고, 해당 payload(실제적으로 전달해야하는데이터)는 로그에 저장되어있다.. 이 로그파일이 클때 데이터를 찾는것에는 많은 비용이 들겠지만, 이를 위해 인덱스 파일이 존재한다.. 이 인덱스 파일에는 어떤 오프셋이 어떤 position에 위치하고잇는지를 알려준다.. 이를 통해서 빠르게 데이터를 읽어나갈수있다..!
https://medium.com/@durgaswaroop/a-practical-introduction-to-kafka-storage-internals-d5b544f6925f

-----------

partition assign 되는과정
1) revoke(물고잇는 파티션 취소)
2) join req(kafka에 join 요청)
3) sucess -> id발급
4) partition 배정

=> 이게 rebalancing .. 하나라도 rebalancing 일어나면 모두가 바뀜.. 반드시 이전에 물고있던 partition을 보장하지않음

****ConsumerRebalanceListener***
onPartitionsRev

*********************************

spring-kafka ConsumerTemplate 설명 굿
https://bistros.tistory.com/entry/springkafka%EC%97%90%EC%84%9C-%EA%B5%AC%ED%98%84%EB%90%98%EC%96%B4-%EC%9E%88%EB%8A%94-MessageListenerContainer

딱딱하지만 자세한설명
https://docs.spring.io/spring-kafka/docs/1.0.0.RC1/reference/htmlsingle/#_message_listener_containers


Consume할때 다시 데이터 불러오는 로직
https://stackoverflow.com/questions/39536012/reading-the-same-message-several-times-from-kafka 

Consumer 다양한 구현형태 정리
https://www.programcreek.com/java-api-examples/index.php?api=org.springframework.kafka.core.ConsumerFactory


kafka cli에서 offset reset 하는 명령어
kafka-consumer-groups --bootstrap-server <host:port> --group <group> --topic <topic> --reset-offsets --to-earliest --execute

kafka-consumer-groups --bootstrap-server 172.16.0.55:9092,172.16.0.55:9094,172.16.0.55:9095 --group groupId --topic test --reset-offsets --to-earliest --execute


토픽 보관주기 설정
./kafka-configs.sh --zookeeper localhost:2181 --alter --entity-type topics --entity-name jeremy_test93 --add-config retention.ms=3600000
./kafka-configs.sh --zookeeper localhost:2181 --alter --entity-type topics --entity-name jeremy_test93 --delete-config retention.ms=3600000
*확인
./kafka-topics.sh --zookeeper localhost:2181 --topic jeremy_test93 --describe

****************CONSUME 만들때 참고할것..****************
-max_poll_record_config를 1(한개 데이터씩 가져온다..는 룰!)로 안놓으면 데이터 하나씩 처리하면서 다음꺼 기다려야할때 불가능.. 이전에 poll로 계속 데이터를 땡겨오는데 여러개를 땡겨오니깐 seek가 정상작동을안함.. 이미 seek해야할 record값은 넘어가있음..

-ConcurrentMessageListenerContainer 는 topic을 한번에 여러개받을수있는데, 만약 seek을 재조정하는 topic이 있다면 다른 topic으로 찾는다..

-Rebalancing 시간 줄이는 방법 : https://stackoverflow.com/questions/46131065/kafka-consumer-rebalancing-takes-too-long

-어노테이션으로 만들때 seek이랑 ack 모두 할수있는 방법

    Starting with version 2.0 there is ConsumerAwareMessageListener to consider on the matter: https://docs.spring.io/spring-kafka/docs/2.0.0.RC1/reference/html/_reference.html#message-listeners

    And @KafkaListener method can be supplied with the Consumer<?, ?> argument:

            @KafkaListener(id = "qux", topics = "annotated4", containerFactory = "kafkaManualAckListenerContainerFactory",
                            containerGroup = "quxGroup")
            public void listen4(@Payload String foo, Acknowledgment ack, Consumer<?, ?> consumer) { ... }

    Let us know if that is OK with you.

    Right, there is nothing to do with that in the previous versions.
    But I think your idea about KafkaMessageListenerContainer.position(TopicPartition) API makes sense.

    출처 : https://github.com/spring-projects/spring-kafka/issues/431

-인터페이스 설명 굿 : 4.1.3. Receiving Messages - (1) MessageListenerContainer - https://shining-life.tistory.com/m/3

-동적으로 listener 생성방법..
https://soon-devblog.tistory.com/19

-batch listener : Spring Kafka Batch Listener - https://brunch.co.kr/@springboot/322
    =>list 형식으로 가져와서 병렬처리가 가능하기에 이를 활용하면 속도를 극대화할수있음..
    =>이게 겁나빠르긴한데.. seek을 하는부분이 애매.. topic을 하나만 가져온다면 상관없겠지만.. topic 여러개 있을때는 poll로 땡겨받은 모든 topic의 record 대해 seek을 해야함... 개별적으로하기가 난해.. ack도그렇고..

-Spring Kafka Retry - https://gunju-ko.github.io/kafka/spring-kafka/2018/04/16/Spring-Kafka-Retry.html

-consumerRebalanceListener : rebalance일어나기전에 해야할 작업들을 정의
    - ConsumerRebalanceListener 인터페이스는 Consumer가 파티션을 직접 할당하지 않고, 컨슈머 그룹 개념을 사용해서 파티션이 자동으로 할당 되도록 했을 경우만 사용할 수 있다. 
        만약 파티션을 직접 할당 했다면, 재조정은 발생하지 않으며 콜백 메소드는 호출되지 않는다.
        onPartitionRevoked 메서드가 실행되고 onPartitionAssigned 실행된다..
        따라서 onPartitionRevoked될때 메소드에서 오프셋을 저장하고 onPartitionAssigned될때 저장된 오프셋을 읽어서 지정하는것이 좋다고한다..
    - onPartitionsRevoked 함수에서 넘겨주는 partitions 파라미터는 rebalancing 하기전 Consumer 클래스가 물고있는 topic의 partition들이다.. 즉, rebalancing할때 revoke되는 파티션만 전달받음
    *추가로 해당 인스턴스를 구현할때 consumer를 같이 넘겨주게되면, Rebalancing 일어나기직전의 offset들을 저장가능..


출처 : https://gunju-ko.github.io/kafka/2018/04/02/Kafka-Offsets.html

****************************************************** 



****************Topic 한번에 혹은 하나씩 지우는방법******************
Here are the steps I follow to delete a topic named MyTopic:

1)Describe the topic, and take not of the broker ids
2) Stop the Apache Kafka daemon for each broker ID listed.
3) Connect to each broker, and delete the topic data folder, e.g. rm -rf /tmp/kafka-logs/MyTopic-0. Repeat for other partitions, and all replicas => 위치는 server.properties에 잇음..
4) Delete the topic metadata: zkCli.sh then rmr /brokers/MyTopic  => 그냥 rmr /brokers/topics 이렇게되어있는거 날림..
5) Start the Apache Kafka daemon for each stopped machine
If you miss you step 3, then Apache Kafka will continue to report the topic as present (for example when if you run kafka-list-topic.sh).

Tested with Apache Kafka 0.8.0.
출처 : https://stackoverflow.com/questions/16284399/purge-kafka-topic

****************************************************************


*************************  PRODUCER  ***************************
3) 비동기 전송
프로듀서는 send() 메소드를 콜백과 같이 호출하고 카프카 브로커에서 응답을 받으면 콜백한다. 만약 프로듀서가 보낸 모든 메시지에 대해 응답을 기다린다면 응답을 기다리는 시간이 더 많이 소요된다. 하지만 비동기적으로 전송한다면 응답을 기다리지 않기 때문에 더욱 빠른 전송이 가능하다. 또한 메시지를 보내지 못했을때 예외를 처리하게 해 에러를 기록하거나 향후 분석을 위해 에러 로그 등에 기록할 수 있다.
// 콜백을 사용하기 위해 org.apache.kafka.clients.producer.Callback를 구현하는 클래스가 필요하다.
class PeterCallback implements Callback {
    public void onCompletion(RecordMetadata metadata, Exception exception) {
        if (metadata != null) {
            System.out.println("Partition : " + metadata.partition()
                + ", Offset :" + metadata.offset() + "");
        } else {
            // 카프카가 오류를 리턴하면, onCompletion()는 예외를 갖게 된다.
            // 실제 운영환경에서는 추가적인 예외처리가 필요하다.
            exception.printStackTrace();
        }
    }
}

Producer<String, String> producer = new KafkaProducer<String, String>(props);
try {
    producer.send(new ProducerRecord<String, String>("peter-topic", "Apache Kafka is a distributed streaming platform")
                , new PeterCallback()); // 프로듀서에서 레코드를 보낼때 콜백 오브젝트를 같이 보낸다.
} catch(Exception exception) {
    exception.printStackTrace();
} finally {
    producer.close();
}
전송 방식에 따라 메시지를 보내는 속도 차이가 발생할 수 있다. 운영 중인 환경에 알맞게 동기, 비동기 방식을 선택해 사용하는 것을 추천한다.


출처: https://12bme.tistory.com/529?category=737765 [길은 가면, 뒤에 있다.]


**************************** CONSUME *****************************
@SpringBootApplication
public class So53715268Application {

    public static void main(String[] args) {
        ConfigurableApplicationContext context = SpringApplication.run(So53715268Application.class, args);
        for (int i = 0; i < 2; i++) {
            AnnotationConfigApplicationContext child = new AnnotationConfigApplicationContext();
            child.setParent(context);
            child.register(ChildConfig.class);
            Properties props = new Properties();
            props.setProperty("group", "group." + i);
            props.setProperty("topic", "topic" + i);
            PropertiesPropertySource pps = new PropertiesPropertySource("listenerProps", props);
            child.getEnvironment().getPropertySources().addLast(pps);
            child.refresh();
        }
    }

}


@Configuration
@EnableKafka
public class ChildConfig {

    @Bean
    public Listener listener() {
        return new Listener();
    }

}


public class Listener {

    @KafkaListener(id = "${group}", topics = "${topic}")
    public void listen(String in) {
        System.out.println(in);
    }

}

: partitions assigned: [topic0-0]
: partitions assigned: [topic1-0]

출처 : https://stackoverflow.com/questions/53715268/kafka-spring-how-to-create-listeners-dynamically-or-in-a-loop

    -한글판 : https://soon-devblog.tistory.com/19

다른거 : https://stackoverflow.com/questions/41533391/how-to-create-separate-kafka-listener-for-each-topic-dynamically-in-springboot/48022114
어노테이션 싫어하시는분이 올린거 : http://www.douevencode.com/articles/2017-12/spring-kafka-without-annotations/
            이분이 올려준 github : https://github.com/douevencode/spring-kafka-sample



******************************* admin *********************************

자바에서 topic 생성하는것

    try {

        List<NewTopic> topics = new ArrayList<>();
        /*for (int i = 1; i <= 100; i++) {                   //여러개 한꺼번에 생성도 가능
            topics.add(TopicBuilder.name("jeremy_test" + i)
                    .partitions(2)
                    .replicas(3)
                    .config("retention.ms","86400000")
                    .build());
        }*/

        //토픽셋팅
        topics.add(TopicBuilder.name("testtesttest")   //topic이름 => bsid+"_report"
                .partitions(3)						   //Partition 3으로 고정
                .replicas(2)						   //replicas 2로 고정
                .config("retention.ms","86400000")   //retention.ms 하루로 고정
                .build());

        Map<String, Object> configs = new HashMap<>();
        configs.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, "dev_db:9092,dev_db:9094,dev_db:9095");  //서버 주소
        AdminClient admin = AdminClient.create(configs);
        admin.createTopics(topics).all().get();
    } catch (Exception e) {
        e.printStackTrace();
    }





kafka/bin/kafka-server-start.sh -daemon /home/dennis/kafka/config/server.properties &
kafka/bin/kafka-server-start.sh -daemon /home/dennis/kafka/config/server-2.properties &
kafka/bin/kafka-server-start.sh -daemon /home/dennis/kafka/config/server-3.properties &



kafka/bin/kafka-server-stop.sh /home/dennis/kafka/config/server.properties &
kafka/bin/kafka-server-stop.sh /home/dennis/kafka/config/server-2.properties &
kafka/bin/kafka-server-stop.sh /home/dennis/kafka/config/server-3.properties &






kafka manager 설치
https://m.blog.naver.com/PostView.nhn?blogId=occidere&logNo=221395731049&proxyReferer=https:%2F%2Fwww.google.com%2F

kafka manager / jmx 연동
https://bigdatalab.tistory.com/26

*jmx설정해야함.. 모니터링하게해주는 api..

background nohup ./bin/kafka-manager > /dev/null 2>&1 &




//////////////////토픽 생성 자바소스/////////////////

        Map<String, Object> configs = new HashMap<>();
        configs.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, "dev_db:9092,dev_db:9094,dev_db:9095");
        List<NewTopic> topics = new ArrayList<>();
        for (int i = 3; i <= 100; i++) {
            topics.add(TopicBuilder.name("jeremy_test" + i)
                    .partitions(2)
                    .replicas(3)
                    .build());
        }
        AdminClient admin = AdminClient.create(configs);

        admin.createTopics(topics).all().get();

///////////////////////////////////////////
\



kafka에서 send 하고 callback함수에서 다시 send하면 timeoutexception이 난다.. 대충 이유는 아래와같다함..
    You may get BufferExhaustedException or TimeoutException
    Just bring your Kafka down after the producer has produced one record. And then continue producing records. After sometime, you should be seeing exceptions in the callback.
    This is because, when you sent the first record, the metadata is fetched, after that, the records will be batched and buffered and they expire eventually after some timeout during which you may see these exceptions.
    I suppose that the timeout is delivery.timeout.ms which when expired give you a TimeoutException exception there.

    https://stackoverflow.com/questions/61654578/kafka-producer-callback-exception

    =>콜백함수가 실행 되었을때 동일한 kafka template에 send를 하면안됨.. 다른 아예 새로운 kafkaTemplate이거나 해당 콜백이 종료된이후에 다시 record를 보내야함.. ****** 이유는 좀더 찾아봐야할듯..*******



/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic streams-pipe-output --formatter kafka.tools.DefaultMessageFormatter --property print.key=true --property print.value=true --property print.value=true --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property value.deserializer=org.apache.kafka.common.serialization.LongDeserializer