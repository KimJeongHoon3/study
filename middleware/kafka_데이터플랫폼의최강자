kafka

1장 카프카란 무엇인가

왜쓰나..?
-모든 서비스의 데이터 파이프라인을 하나로 집중시킬수있음 => 데이터 관리 효율적으로 가능, 이로인해 서비스 분석용이
-빠른 처리와 스케일아웃(수평확장성), 고장감내성에 기반한 이벤트 버스 애플리케이션
-비동기 통신 방식으로 매우 빠름 
-빅데이터를 분석할때 여러 스토리지와 분석시스템에 데이터를 연결하기 위한 필수도구!
-end to end 연결방식의 아키텍처에 대한 해결책..
   -데이터파이프라인이 제 각기 있게되서 관리가 매우 힘들다.. 각기 따로 만든 데이터파이프라인을 다른 서비스가 주고받는 일들이 분명생기게되는데, 이에 대해서 엔드투엔드방식은 다른 서비스간 데이터를 주고받기위해서 복잡한 작업이필요하게된다..

카프카동작방식
-중앙에 메세지 시스템 서버를 두고 pub(전송), sub(수신)
 하는 pub/sub 모델

카프카의 특징
-프로듀서와 컨슈머의 분리..
-멀티 프로듀서, 멀티컨슈머
-디스크에 메세지 저장
   -컨슈머가 메세지를 읽어가더라도 정해져잇는 보관주기 동안 디스크에 메세지를 저장해놓음
   -디스크에 저장해놓기때문에 멀티 컨슈머가 가능한구조
   -컨슈머쪽에서 문제가 생겼더라도 디스크에 저장되어있기때문에 데이터 유실의 위험이 현저히 적음
-확장성
   -클러스터의 확장또한 카프카 서비스의 중단없이 온라인상태에서 가능
   
*용어정리
-브로커 : 카프카 애플리케이션이 설치되어있는 서버 또는 노드를 말함
-토픽 : 프로듀서와 컨슈머들이 카프카로 보낸 자신들의 메세지를 구분하기위한 네임
-파티션 : 병렬처리 가능하도록 토픽을 나누는 개념.. 하나의 토픽에 N개의 파티션
-프로듀서 : 메세지를 생산하여 브로커의 토픽이름으로 보내는 서버 또는 앱
-컨슈머 : 브로커의 토픽이름으로 저장된 메시지를 가져가는 서버 또는 앱

카프카의 확장과 발전
-ESB(Enterprise service bus)의 특징을 지님 (서비스 간의 연결은 ESB로!)
   -다양한 시스템과 연동하기위한 멀티 프로토콜과 데이터 타입지원
   -느슨한 결합을 위한 메세지 큐 지원
   -정기적으로 데이터를 가져오는 대신 이벤트 기반 통신 지향
-모든 데이터를 하나로 관리할수있도록 해줌으로써 빅데이터 분석과 머신러닝 플랫폼을 만드는데 중요한 위치등극,,
   -아파치 스톰, 스파크와 연결해서사용가능
   -카프카스트림즈, ksql을 통해 실시간 데이터 분석 가능..

=> 카프카를 사용하면 빅데이터로 활용할수있는 기반을 마련해줄수있음..

----------------

2장 카프카설치

주키퍼
-분산 애플리케이션을 관리하기위한 애플리케이션..
-즉, 여러 서버에 카프카를 설치하게되면 이를 통합적으로 관리할 코디네이션 앱이 필요한데, 주키퍼가 그 역할을 담당한다.
-각 애플리키션의 정보를 중앙에 집중하고 구성관리, 그룹관리 네이밍, 동기화 등의 서비스를 제공한다.
*주키퍼 3대로 앙상블 구성하면 초당 80000, 5대는 14만건 요청처리가능(주키퍼만 이야기하는것)

-------------------

3장 카프카 디자인

-카프카는 분산시스템으로, 단일 시스템보다 더 높은 성능과, 장애 발생시 다른 서버가 처리하는 고가용성, 시스템확장에 용이
-카프카는 높은 처리량과 빠른 메시지 전송, 운영 효율화 등을 위해 분산시스템, 페이지캐시, 배치전송을 구현
   -분산시스템 : 같은 역할을 하는 여러대의 서버로 이루어진 서버 그룹을 분산시스템.. 목표같음.. 목표를 공유하는 서버들이 있는것
      -단일 시스템보다 높은 성능
      -하나의 서버 또는 노드가 죽으면 다른서버 또는 노드가 이를 처리
      -시스템 확장이 용이..
   -페이지캐시 : 메모리를 이용해 디스크에 읽고 쓰기를 하지않고 페이지 캐시를 통해 읽고 쓰는 방식을 사용 => 페이지 캐시를 사용하여 더 빠른 처리속도가능!
      *OS(Operating System)은 메모리에 Application이 사용할 영역을 할당하고 나머지 메모리중의 일부를 페이지 캐시라는 이름으로 불리는 영역을 유지하여 OS의 성능 향상을 꾀하고 있습니다
      남아 있는 메모리를 그대로 이용하지 않고 페이지 캐시를 통해 읽고 쓰는 방식을 사용하면 처리속도가 굉장히 빨라지는데요 이 부분은 전체적인 성능 향상을 가져올 수 있는데 카프카는 이러한 페이지 캐시의 특징을 이용하도록 Design되어졌습니다.
      -출처: https://sugerent.tistory.com/586 [MISTERY]
         => -OS에는 메모리를 할당할때 페이지캐시를 사용해서 반복적인 요청을 빠르게 처리할수있도록해준다... 카프카는 JVM을 사용하는 애플리케이션으로 메시지 처리는 JVM에 할당된 메모리를 이용하여 이루어진다. 
         그리고 이와 별도로 I/O은 페이지 캐시를 이용하여 처리하는데, I/O 를 할 때마다 매번 새로 시작하는 대신 캐시를 유지하여 작업을 한다면 시간을 절약할 수 있기 때문이다. 
         즉, 카프카에서 Heap 메모리를 할당할 때에는 물리 메모리를 전부 할당해서는 안 되고, 이 페이지 캐시부분 메모리를 감안하여 적당한 양을 할당하여야 한다.


      =>즉, 디스크에 직접 읽고쓰는것이 아닌, 페이지캐시를 통해서 읽고쓴다.. 
         producer가 메세지를 전송하게되면 일단 페이지캐시에 데이터를 쓰는데, Acks=1일때는 페이지캐시에 데이터를 쓰는것을 완료했다면 바로 응답을준다! 디스크에 복제가 다 끝났는지는 확인하지않는다! 
         페이지 캐시는 무튼 메모리를 차지하는것이고, OS의 메모리가 부족하면 이런 캐시로 할당된 메모리를 다시 가져와서 사용한다.. 그렇기에 Kafka의 데이터 읽기쓰기의 속도에 안좋은 영향을 미치지않기위해서는 일정 메모리를 페이지캐시가 쓰도록해주어야함!

           카프카 <-> 페이지캐시 <-> 디스크

        consumer할때 제로카피!(파일시스템의 캐시를 중간버퍼에 쓰지않고 바로 네트워크 채널로 전송)
         페이지캐시에 대한 자세한 정리는 "리눅스폴더 안의 "페이지 캐시" 참고"
      
         
   -배치전송처리 : 클라와 서버 또는 서버 내부적으로 데이터를 주고받는 과정에서 I/O가 빈번하게 일어나면 속도저하를 가져올수있기때문에 카프카에서는 작은 메시지들을 한번에 묶어서 보내는 배치처리를 사용
    
-토픽 : 메세지를 받는 주소라고 생각하면됨..
-파티션 : 하나의 토픽에 여러 파티션을 둘수있는데,이는 파티션 갯수만큼 병렬처리가 가능하게함.. (producer도 그만큼 늘려야...한다고 책에나와있음..)
   -파티션수 어디까지 늘리는게 효율적???
      -파티션을 무조건 늘리면, 장애시 복구에 대한 시간이 증가하게된다.. 예를들어 1000개의 파티션을 가진 브로커가 다운이되었을때, 다른 브로커에서 리더를 선출하는 시간 비용이 파티션이 증가된 만큼 나타나게된다..

   -카프카에서 브로커당 약 최대 2000개의 파티션을 권장
??????????????????????? 
카프카에서 컨트롤러(브로커)   
=> 브로커중 하나가 컨트롤러가 되어서 브로커 레벨에서 실패를 감지하고 실패한 브로커에 의해 영향받는 모든 파티션의 리더 변경을 책임짐..

*컨트롤러
-브로커들 중에서 선정
-다른 브로커들의 상태를 체크..
-죽은 브로커가 보이면, 그 브로커가 담당한 파티션의 새 리더를 선출..
-새롭게 선출된 리더 정보를 모든 브로커에게 전달..
-브로커들을 관리하는놈..
-컨트롤러 브로커는 파티션의 리더가 어떻게 되는지, 팔로워는 누구인지를 정한다.. (그리고 주키퍼한테 알려주나..?)
-컨트롤러 브로커가 죽었을때는 주키퍼는 새로운 컨트롤러 브로커를 선정한다.. (브로커가 요청하면 주키퍼의 /controller znode에 브로커 id가 새로이 등록됨.. 이미 등록되어있으면 컨트롤러가 정해진것이므로 익셉션을 발생시키나 하여튼 컨트롤러가 이미 정해져있으니 꺼지라고함)

-컨트롤러의 책임
   -컨트롤러 브로커는 토픽의 모든 파티션에 대한 리더/팔로워 관계를 설정한다. 카프카 노드가 죽거나 (주키퍼 하트 비트에) 응답하지 않으면, 할당된 모든 파티션(리더와 팔로워 모두)이 컨트롤러 브로커에 의해 재할당 된다.
   -컨트롤러 브로커는 일부 토픽/파티션은 리더가 되도록, 그 외에는 팔로워가 되도록 브로커에 할당하는 책임을 갖는다. 브로커를 사용할 수 없게 되면 컨트롤러 브로커는 있던 파티션을 클러스터의 다른 브로커에게 재할당 한다.
   https://12bme.tistory.com/521
 
????????????????????????

-----------------------
4장 producer

-주요옵션
    -bootstarp.servers : 전체 카프카 리스트를 적음.. 호스트 하나만 사용해도되기는하지만, 클라이언트는 해당 호스트가 죽었을경우 다른 호스트로 재연결을 시도하여 문제가 없도록 해주기때문에 리스트모두를 적어라
    -acks : 카프카 토픽의 리더에게 메시지를 보낸후 요청을 완료하기 전 ack(승인)의 수.. 옵션수가 크면 메시지 손실 가능성 적음.. 그러나 느림..
        - acks=0 : 카프카 서버로부터 어떤 응답도 기다리지않는다. 매우빠르지만 안정x
        - acks=1 : 카프카의 리더로 데이터가 잘 기록되었는지까지만 보장.. 팔로워들은 x
        - acks=-1 or all : 팔로워들까지 모두 보장.. 제일느리지만 손실확률 거의 0
        => acks를 잘 활용하려면 kafka server의 설정도 신경을 써야한다.. acks는 producer의 설정이고, kafka server의 min.insync.replicas 의 값을 지정해서 최소 ack를 받는 수를 지정할수있다.. 
        만약 하나의 토픽에 partition은 3개이고, min.insync.replicas가 2일때 acks=all로 하였다면, 모든 팔로워가 데이터를 복제할때까지 기다렸다가 ack를 보내는것이아니라, 리더가 데이터를 저장했고, 두 팔로워중에 하나만 데이터를 저장했다면 ack를 바로 보내게되는것이다..(최소 replica가 2개 만족되었으므로!!)
    
    -buffer.memory : 카프카 서버로 데이터를 보내기 위해 잠시 대기할수있는 전체 메모리 바이트..
    -compression.type : 프로듀서가 데이터를 압축해서 보낼수 있음.. none, gzip, snappy, lz4 같은 다양한 포맷지원 
    -retries : 일시적인 오류로 인해 전송에 실패한 데이터를 다시 보내는 횟수
    -batch.size : 같은 파티션으로 보내는 여러 데이터를 함께 배치로 보내려고 시도.. 배치 크기 바이트 단위를 조정.. 정의된 크기 보다 큰 데이터는 배치를 시도x,, 
    -linger.ms : 배치 형태의 메세지를 보내기위해 추가적인 메세지를 기다리는 시간.. default가 0 이기때문에 기본적으로 batch size보다 작게 데이터가 쌓여잇어도 데이터를 바로바로 보낸다..


-프로듀서가 send할때 어떻게 가는지..
https://leeyh0216.github.io/2020-05-03/kafka_producer
KafkaProducer의 send를 호출하게 되면 ProducerRecord를 KafkaProducer의 내부 Buffer에 저장해놓은 후, 어느정도 메시지가 모이게 되면 여러 개의 메시지를 한번에 보내고 Callback을 호출한다.
accumulator라는놈이 메세지를 쌓아주게되면, sender가 RecordAccumulator 로부터 fetch(가져오다..) 하여 broker로 전송한다...    

-중복 전송 (참고사이트 : https://sjh836.tistory.com/186)
   -브로커 응답이 늦게와서, 재시도하는 경우, 중복으로 메세지가 전송될 수 있음 (ex. timeout)
   -enable.idempotence 옵션으로 중복전송 가능성을 낮출 수 있음
   -max.in.flight.requests.per.connection 옵션 : 하나의 커넥션에서 전송할 수 있는 최대 전송중인 메세지 수
      -이 값이 1보다 크다면, 재시도 시점에 메세지 순서가 뒤바뀔수 있음
      -전송 순서가 중요하다면, 이 값을 1로 해야함


출처: https://sjh836.tistory.com/186 [빨간색코딩]

--------------------

5장 컨슈머

-주요기능 : 파티션 리더에게 메세지 가져오기를 요청함.. 각 요청은 로그의 오프셋을 명시하고 그 위치로부터 로그 메세지를 수신.. 그래서 어디서 부터 가져올지를 지정할수있음.. 즉, 위치만 알고있다면 이전데이터를 가져올수도잇음

-주요옵션
    -bootstrap.servers : producer와 동일
    -fetch.min.bytes : 한번에 가져올 수 있는 최소 데이터 사이즈.. 만약 지정한 사이즈보다 작으면 데이터가 누적될때까지 기다림..
    -group.id : 컨슈머 그룹을 식별하는 식별자
    -enable.auto.commit : 백그라운드로 오프셋 주기적으로 커밋할지말지
    -auto.offset.reset : 카프카에서 초기 오프셋이 없거나 현재 오프셋이 더 이상 존재하지않는 경우(데이터 삭제되었을때..?)에 다음 옵션으로 reset
        -earliest : 가장 초기의 오프셋값으로 설정
        -latest : 가장 마지막의 오프셋값으로 설정
        -none : 이전 오프셋값을 찾지 못하면 에러
    -fetch.max.bytes : 한번에 가져올수 있는 최대 데이터 사이즈
    -request.timeout.ms : 요청에 대해 응답을 기다리는 최대시간
    -session.timeout.ms : 컨슈머와 브로커 사이의 세션 타임아웃시간.. 컨슈머는 그룹코디네이터(컨슈머 그룹을 관리하는..?)에게 특정 동작때 하트비트를 보내게되는데, 하트비트가 세션 타임아웃 시간보다 늦게오면 브로커는 문제가 있는 컨슈머로 판단하여 연결은 끊고 리벨런싱을 진행.. 
        *그룹코디네이터 : 컨슈머 그룹을 관리하기위한것으로 현재컨슈머(새컨슈머)는 카프카 자체로 만든 그룹 코디네이터 프로토콜을 사용한다..
            //-브로커중에 하나가 코디네이터로 선택이되고, 코디네이터는 그룹의 상태를 관리할 책임이 있고, 새로운 멤버가 추가될때와 토픽메타데이터가 변할때 파티션할당을 중재하는것이다.. 이를 리벨런싱이라한다..
            -브로커에는 하나의 코디네이터가 있고, 컨슈머 그룹의 리더를 선정해준다.. 컨슈머 그룹의 리더를 선정할때는 그룹의 모든 컨슈머가 첫 poll 함수를 호출하였을때 진행이 이루어지는데, 코디네이터가 리더를 선정해주고 모든 컨슈머에 대한 정보를 전달해주면(코디네이터에게 먼저 Poll을 보낸애가 되는듯함..) , 리더가 컨슈머들이 어떤 파티션을 배정받게 될지에 대해 코디네이터에게 통보한다. 그럼 코디네이터는 전달받은대로 파티션을 컨슈머에게 엮어준다..
            -만약, 새로운 컨슈머가 추가되거나 종료되엇을때, 컨슈머들은 poll함수를 시작으로 코디네이터로부터 다시 리더를 선정받고 어떤 파티션으로 배정받게될것인지를 반복하게된다..
                -poll을 하는 갯수가 많거나 처리하는 양이 많다면 리밸런싱이 일어나야하는 순간에 한창 poll하고있는 컨슈머가 있다면, 해당 컨슈머가 다시 poll할때까지 기다렸다가 진행이되므로, 성능에 좋지않을수있다.. 즉 Record를 몇개씩 가져올것인지 잘 조절하는것이 리밸런싱하는데 중요..
                -즉 rebalancing은 poll함수 진행 중간에 끊어서 실행되는것이아닌 poll함수가 끝나야 진행!
            -여기서 컨슈머는 코디네이터에게 하트비트를 보내서 내가 살아있음을 알리게되는데, session.timeout.ms에서 지정한 시간안에 코디네이터가 하트비트를 받지못하면 해당 컨슈머는 장애가 일어났다고 생각하여 연결을 끊고 리벨런싱이 일어나게된다..
                -만약 poll을 하여 데이터 처리하는 시간이 길어지면, 하트비트를 코디네이터가 못받을수있으므로 본의아니게 리밸런싱이 일어남.. 
                (-3초에 한번씩 하트비트를 전용으로 보내는 스레드가 있기때문에 위의 내용은 크게신경안써도될듯.. 아마 버전업하면서 변경이되었다고했던거같음..
                  관련 내용 그림&글 : https://chrzaszcz.dev/2019/06/kafka-heartbeat-thread/)
        https://medium.com/11st-pe-techblog/%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%BB%A8%EC%8A%88%EB%A8%B8-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EB%B0%B0%ED%8F%AC-%EC%A0%84%EB%9E%B5-4cb2c7550a72    

        아파치에서 설명한 코디네이터 디자인 : https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Detailed+Consumer+Coordinator+Design#KafkaDetailedConsumerCoordinatorDesign-5.OnCoordinatorStartup


        소비자 그룹 코디네이터는 브로커 중 하나이며 그룹 리더는 소비자 그룹의 소비자 중 하나입니다.
        그룹 코디네이터는 소비자 그룹의 모든 소비자로부터 하트 비트 (또는 메시지 폴링)를받는 브로커 중 하나 일뿐입니다. 모든 소비자 그룹에는 그룹 코디네이터가 있습니다. 소비자가 하트 비트 전송을 중지하면 코디네이터가 재조정을 트리거합니다.
        소비자는 소비자 그룹에 가입하려고 할 때 그룹 코디네이터에게 JoinGroup 요청을 보냅니다. 그룹에 가입 한 첫 번째 소비자가 그룹 리더가됩니다. 리더는 그룹 코디네이터로부터 그룹의 모든 소비자 목록을받습니다 (최근에 하트 비트를 전송하여 살아있는 것으로 간주되는 모든 소비자가 포함됨).
        각 소비자에게 파티션의 서브 세트를 할당 할 책임이 있습니다. PartitionAssignor 인터페이스의 구현을 사용하여 어떤 소비자가 어떤 파티션을 처리해야하는지 결정합니다. 파티션 할당을 결정한 후 소비자 리더는 할당 목록을 GroupCoordinator로 보내며이 정보를 모든 소비자에게 보냅니다.
        각 소비자는 자신의 할당 만 볼 수 있습니다. 리더는 그룹의 전체 소비자 목록과 할당이있는 유일한 클라이언트 프로세스입니다. 이 과정은 재조정이 발생할 때마다 반복됩니다.
        출처 : https://stackoverflow.com/questions/42015158/what-is-the-difference-in-kafka-between-a-consumer-group-coordinator-and-a-consu 

        **하트비트는 poll할때와 오프셋을 커밋할때 보내게된다!!!!!!!**


    -heartbeat.interval.ms : 그룹 코디네이터에게 어느 주기로 하트비트를 보낼것인지 조정하는것.. 보통 session.timeout.ms의 1/3 정도로 설정함.. (별도 스레드가 돌아감.. poll과 상관없이!)
    -max.poll.records : poll에 대한 최대 레코드 수 조정
    -max.poll.interval.ms : 코디네이터에게 하트비트는 주기적으로보내서 문제없는듯하나, 실제로 poll을 하지않고 있을수 잇으므로 이 설정을 통해서 해당 interval동안 poll을 하지않으면 장애로 판단하여 그룹에서 제외
                           -> poll해서 데이터 처리하는시간이 해당 설정값보다 초과되면 문제생긴걸로 간주하고 카프카가 연결끊는다.. poll() -> max.poll.interval.mx 시간안에 데이터 처리 -> poll()
    -auto.commit.interval.ms : 주기적으로 오프셋을 커밋하는 시간
    -fetch.max.wait.ms : fetch.min.bytes에 의해 설정된 데이터보다 적은 경우 요청에 응답을 기다리는 최대시간.. (이거 넘어가면 바로 메세지 전송하겠지..) 

-파티션을 여러개로 분산되어있는것들을 consuming하면 당연히 순서보장안댐.. 순서보장해야한다면 파티션을 하나만 써야함
-컨슈머 그룹안에는 여러 컨슈머를 등록할수있는데, 이렇게 여러 컨슈머를 두게됨으로써 동일한 토픽에 대해서 빠른 처리가 가능하다.. 하지만, 하나의 파티션에 하나의 컨슈머가 매칭될수있다(하나의 컨슈머가 여러 파티션은 가능,, 하지만 반대는 불가능 - 하나의 파티션안에는 순서가 보장되어야하는것에 맞지않음!)
-커밋과 오프셋
    -컨슈머 그룹의 컨슈머들은 각각의 파티션에 자신이 가져간 메세지의 위치정보(오프셋)을 기록.. 각 파티션에 현재 위치를 업데이트하는 동작을 커밋이라함
    -auto commit : auto commit으로 정해진 시간이 지났을때 poll을 한 시점에 commit이 이루어진다.
    -seek함수를 사용하여 다시 kafka에서 받은데이터를 다시 가져올수있음

-컨슈머가 partition assign하는 과정
    1) 현재 가지고 있는 파티션 Revoke 
    2) 컨슈머가 group coordinator에게 join group을 요청
    3) 그룹 코디네이터가 컨슈머그룹의 리더에게 해당그룹에 있는 컨슈머들의 모든 리스트들(하트비트 보내서 살아있는놈)을 전달해주고 전달받은 리스트를 토대로 어떤 컨슈머에게 어떤 파티션이 배정될지를 리더가 결정해서 그룹 코디네이터에게 전달,, (해당 컨슈머 그룹에 1빠로 들어온놈이 리더임.. 이 리더는 컨슈머에게 파티션 할당하는 역할을하고 이 파티션할당이 이렇게됐다고 코디네이터그룹에게 전송.. )
    4) 그룹 코디네이터는 전달받은 정보들을 토대로 모든 컨슈머들에게 매칭된 파티션을 알려줌 (generation 정보화 함께 join 성공,, 리더만이 컨슈머그룹의 모든 컨슈머 정보를 가지고있고, 나머지 컨슈머들은 자신만알고있음..)
        -generation은 모든 컨슈머가 공유하게되는데, Rebalancing이 일어나면 하나씩 증가.. (컨슈머 하나가 컨슈머 그룹의 generation에 join 되는개념.. )
    5) 컨슈머는 파티션 할당 및 offset 전달받음
   *참고 : 컨슈머 그룹이 다르면 당연히 서로간에 리벨런싱은 이루어지지않는다.. 
          컨슈머ID는 프로그램실행시 새로부여됨..

   **그룹코디네이터(브로커중 하나) <-> 컨슈머 그룹의 리더 <-> 컨슈머들..(컨슈머중에 제일먼저 그룹에 join된 놈이 리더역할을하게됨..)
                            
   아래는 위의 내용을 설명한 원본글
When a consumer wants to join a consumer group, it sends a JoinGroup request to the group coordinator. The first consumer to join the group becomes the group leader. The leader receives a list of all consumers in the group from the group coordinator (this will include all consumers that sent a heartbeat recently and are therefore considered alive) and it is responsible for assigning a subset of partitions to each consumer. It uses an implementation of the PartitionAssignor interface to decide which partitions should be handled by which consumer.
[...] After deciding on the partition assignment, the consumer leader sends the list of assignments to the GroupCoordinator which sends this information to all the consumers. Each consumer only sees his own assignment - the leader is the only client process that has the full list of consumers in the group and their assignments. This process repeats every time a rebalance happens.


---------------------
6장 카프카 운영가이드 (주키퍼나 카프카 스케일아웃할때 꼭 책 확인할것!!)
-producer에서 특정key로 데이터를 보내고있다면, 파티션이 증가할때 주의해야한다.. 왜냐하면 해당 key가 몇번째 몇번째파티션에 배정될지 모르기때문이다..
-카프카 스케일 아웃을 할때 파티션을 분산하는 작업을 하면 복제 되는 Topic의 파티션 크기가 크면 상당히 시스템에 부하가 많이가게되므로, 토픽보관주기를 줄여서 파티션을 가볍게 하고, topic 사용시간이 가장적을때 하는것이 좋다

-----------------------
7장 카프카를 활용한 데이터 파이프라인 구축
-file beat : 경량데이터 수집기.. 데이터받아서 카프카로 producer가능
-nifi : 웹 인터페이스 형태로 데이터 처리가능.. 카프카 컨슘, 프로듀싱, 하둡으로 전달 등등 웹에서 GUI로 겁나많은 데이터 처리가능
-elastic search : 엘라스틱의 분산형 restful 검색 및 분석엔진
-kibana : 엘라스틱서치에 저장된 데이터 확인, 분석을 도와줌

-----------------------
8정 카프카 스트림즈 api
-스트림 프로세싱 : 데이터들이 유입되고 나가는 과정에서 이 데이터에 대한 분식이나 질의를 수행하는 것을 의미.. 
    *이와 반대되는 개념으로 배치처리 또는 정적데이터처리가 있는데, 이는 데이터를 모아놨다가 특정시간에 처리하는것..




찾아보아야할것들
-스플렁크 (이를 기반으로 로그수집??)

--------------------
수정할것
-kafka send하는쪽 수정할것.. 
   -fault던지는부분 따로 가져갈것
   -메세지 던지는 부분 future패턴사용해서 실패일때 바로 클라이언트에 응답보내도록 로직수정..






*****************

kafka.. 좀더 정리가 필요해서 정리..
-주키퍼 : 분산시스템을 다룰수있도록 해줌..
   *주키퍼 3대로 앙상블 구성하면 초당 80000, 5대는 14만건 요청처리가능(주키퍼만 이야기하는것)

??
https://brunch.co.kr/@timevoyage/77
-분산 시스템을 사용하게되면 OS나 네트워크 상태에 따라서 상당히 많은이슈들을 마주하게될수있는데, 이때 개발자들이 동기화를 비롯한 부수적인 요소 대신 서비스가 제공하는 기능과 그 구현방법에 좀더 집중할수있도록 도와주는것이 주키퍼의 역할이다
-주키퍼는 트리구조로 데이터를 보관할수있다.. ex) controller/id ..
-그러나 많은 양의 데이터를 보관하는데는 적합하지않음..
-개발자가 주키퍼에 저장해야할 정보는 제어 또는 조율을 위한 데이터..
-서버들의 설정 정보 또는 클러스터를 구성할때 마스터가 어떤 서버인지, 각각의 작업에 할당되어 있는 서버가 무엇인지 등의 정보가 바로 주키퍼가 다루는것들.. 즉, 카프카로 보면 브로커들에 대한 정보.. 브로커레벨이므로 조금은 큼직한느낌..? 토픽의 데이터들을 저장하는것은 아니라는거! 
-개발자는 주키퍼 api를 이용해 동기화나 마스터 선출 등 몇몇 골치 아픈 작업을 쉽게 구현할수있는것!!
-주키퍼 장점
   -일관성, 순서, 지속성을 보장..
   -동기화를 위한 프리미티브를 구현가능(무슨말?)
   -분산 시스템에서 동시성으로 인해 생기는 잘못된동작 차단..
-주키퍼에서 znode를 생성할때는 4가지 모드가있다.
   -persistent : 영속 - 직접 delete로 지우지않는한 znode는 없어지지않는다..
   -ephemeral : 임시 - 세션끊키거나하면 사라짐,, 그래서 자식노드는 가질수없음
   -persistent_sequential : 영속 + 생성할때 이름에 정수가 순차적으로붙여준다.. 알아서..
   -ephemeral_sequential : 임시 + 생성할때 이름에 정수가 순차적으로붙여줌..
-와치 & 알림
   -주키퍼는 다른 클라이언트의 변화를 감지하면 해당 변화를 클라이언트에 전달해준다.. 클라이언트에서 api를 호출하여 poll 하는 방식도 잇지만, 지속적인 poll은 결국 계속 api를 호출하는것이기 때문에 자원낭비일수밖에없다.. 그래서 watcher를 등록하여 알람(notification)을 받을수 있도록 설계되어있다.
-주키퍼구조
   -스탠드어론(standalone) : 하나의 주키퍼서버가 잇는것.. 복제하는 작업은 없다..
   -쿼럼(quorum) : 서버 여러대가 하나의 앙상블을 구성.. 각각의 주키퍼가 가지고 있는 상태를 복제하여 일관성을 유지..
      -클라이언트 요청을 각기 다른 서버가 받을수 있도록 구성하고 있기때문에 클라이언트의 요청에 대한 처리량도 증가.. 
      -클라이언트와 연결이 끊어졌을경우 다른 서버로 알아서 연결해줌..
      -복제를 통해서 데이터 일관성을 유지..
      -과반 이상이 살아남으면 그대로 진행됨..
-세션 
   -주키퍼 클라이언트가 기존 서버와 끊어지고 다른 서버에 연결될 경우, 서버가 가지고 잇는 상태를 확인한다..
   -주키퍼는 트랜잭션 아이디를 이용해서 변경된 상태를 순서대로 정렬하며 가지고있는 정보가 최신인지 확인 가능하도록 도와준다.
   -주키퍼 클라이언트가 서버와 끊어졌을때 zxids가 1이라면, 다시 붙으려면 서버의 zxids는 1보다 커야지 접속이 가능하다..
-주키퍼 사용예
   -Master-Worker 서버를 구성하면서 클라이언트가 요청한 작업을 할당할 때 주키퍼가 사용될수있다.. 마스터로 지정된 서버 정보를 주키퍼가 가지고있고, 워커가 생성되면 워커의 주소를 주키퍼에 등록한다... 
   클라이언트는 요청할 작업을 주키퍼에 등록하기만 하면, 마스터가 작업을 워커에 할당하고, 할당한 내역을 주키퍼에 기록하면서 요청을 처리한다... 
   서버간 직접적인 통신 없이 주키퍼를 사용하기 때문에 개발자는 동기화나 데이터 복제 등 골치아픈 문제에 대해 생각하지않아도댐

-카프카 에서의 주키퍼
주키퍼는 카프카 운영의 다음 측면에도 관여한다.
 - 클러스터 멤버십: 클러스터에 가입하고 클러스터 멤버십을 유지 관리한다. 브로커를 사용할 수 없게 되면 주키퍼는 클러스터 멤버십에서 브로커를 제거한다.
 - 토픽 설정: 클러스터의 토픽을 트래킹한다. 브로커가 토픽의 리더인지, 토픽에 파티션이 몇개인지, 토픽의 특정 설정이 업데이트됐는지 확인한다.
 - 접근 제어: 특정 토픽에 대해 누가 읽고 쓸 수 있는지 식별한다.
 카프카가 팔로워들과 리더 브로커를 가질 수 있게 하는 것이 주키퍼다. 컨트롤러 브로커는 복제를 위해 토픽 파티션을 팔로워에게 할당하는 것은 물론 멤버로 있던 브로커가 실패할 때 이를 다시 지정하는 중요한 역할도 한다.
  https://12bme.tistory.com/521











consumer가 poll을 할때 어떤흐름으로 처리되는지.. 컨트롤러를 가게되는지.. 컨슈머가 직접적으로 파티션에 붙어서 가져오는지.. 아니면 컨트롤러가 중간에 관여를 하는지..

-------------

카프카 스트림즈

-스트림 프로세싱 : 스트림 처리는 처리할 데이터를 수집하거나 저장할 필요없이 무한히 데이터 스트림을 유입되는 대로 연속으로 계산해 처리할 수 있는 능력이라고 정의한다.
-상태기반 vs 무상태기반 스트림
    -상태기반 : 이전스트림의 처리결과를 참조하는경우... 이런 상태를 저장하는곳을 상태저장소라하고 앱 내부에 저장소가있으면 내부상태저장소, DB와 같이 별도의 저장소를 사용하면 외부상태저장소를 사용한다고함
        ex) 단어 빈도수세기, 실시간 추천프로그램
    -무상태기반 : 이전 스트림 처리의 결과와 관계없이 현재 앱에 도달한 스트림만을 기준으로 처리하는것

-카프카스트림즈는 토폴로지를 마늘어서 처리하는 api.. (프로세서들이 서로연결)
-카프카 스트림즈 토폴로지 용어 정리
    -스트림 : 카프카 스트림즈 api를 사용해 생성된 토폴로지로, 끊임없이 전달되는 데이터 세트를 의미.. 스트림에 기록되는 단위는 키-값 형태
    -스트림 처리 애플리케이션 : 카프카 스트림 클라이언트를 사용하는 애플리케이션,, 하나 이상의 프로세서 토폴로지에서 처리되는 로직을 의미하기도함..
        *프로세서 토폴로지 : 스트림 프로세서가 서로 연결된 그래프
        **스트림 프로세서 : 프로세서 토폴리지를 이루는 하나의 노드.. 입력스트림으로부터 데이터를 받아서 변환한 다음 다시 연결된 프로세서에 보내는 역할..
    -소스프로세서 : 위쪽으로 연결도니 프로세서가 없는 프로세서.. 카프카 토픽에서 데이터 레코드를 읽어서 아래쪽 프로세서에 전달
    -싱크프로세서 : 토폴리지 아래쪽에 프로세서가 없는것을 말함.. 상위프로세서로부터 받은 데이터 레코드를 카프카 특정 토픽에 저장..

-------------

카프카 SQL을 이용한 스트리밍 처리
- 데이터를 모으는것(또는 전송하는것)뿐아니라 KSQL을 통해서 스트리밍과 배치처리도 가능
- 람다 아키텍처
- 카파 아키텍처 
- 구성 : kafka <-> KSQL server <-> KSQL 쉘 클라이언트 
    - stream, 쿼리결과로 스트림(stream 만들되, as select..), table 을 create 하도록 sql 명령할수있음..
    -


-----------
카프카 에러 정리 : https://springboot.cloud/35


