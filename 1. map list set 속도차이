1. map list set 속도차이
-시간복잡도 
    -https://soft.plusblog.co.kr/74
    -ArrayList
        -시간복잡도
            -add : O(1)
            -remove : O(n)
            -get : O(1) => 인덱스로 바로 찾기때문에 겁나빠름
            -contains : O(n)
        -특징
            -데이터 추가, 삭제를 위해 임시 배열을 생성해 데이터를 복사
            -대량의 자료를 추가/삭제시 복사가 일어나게되어 성능저하 일어남
            -데이터의 인덱스를 가지고있어서 검색에 빠름
    -Hashmap
        -시간복잡도
            -get : O(1)
            -containsKey : O(1)
            -next : O(m/n) //hash collision으로 해당 저장소에 linkedList로 저장할경우,, key의 수를 m , 저장소 길이가 n => 1개의 hash당 들어있는 key의 갯수 
        -특징
            -HashMap과 HashTable을 정의한다면, '키에 대한 해시 값을 사용하여 값을 저장하고 조회하며, 키-값 쌍의 개수에 따라 동적으로 크기가 증가하는 associate array'라고 할 수 있다. 이 associate array를 지칭하는 다른 용어가 있는데, 대표적으로 Map, Dictionary, Symbol Table 등이다.
            -java 1.8버전으로 확인해본바 하나의 hash값의 8개 이상의 node가 들어가있다면 이를 트리형태로 변경! 즉 하나의 해시 버킷에 8개의 키-값 쌍이 모이면 링크드 리스트를 트리로 변경한다. 만약 해당 버킷에 있는 데이터를 삭제하여 개수가 6개에 이르면 다시 링크드 리스트로 변경한다.
            -key값이 달라도 버킷에 동일한 데이터가 들어가게될수있음! 버킷이 처음에 많이 생성안되면!! 처음에 16개 생성되는듯함..
                if ((p = tab[i = (n - 1) & hash]) == null)  //여기서 hash는 key값의 hash값에 쉬프팅된것.. 처음에 n은 16.. 긍까 String이 달라도 버킷이 많지않기때문에 같은 버킷으로 저장될수있다!!
                    tab[i] = newNode(hash, key, value, null);
            
    -treemap
        -시간복잡도
            -get : O(log n)
            -containsKey : O(log n)
            -next : O(log n)
        -특징
            -key가 정렬이 되어 저장
            -검색시 tree를 사용하기때문에 log n의 시간 복잡도 사용..

    -HashSet
        -시간복잡도
            -add : O(1)
            -contains : O(1)
            -next : O(m/n)  //hash collision으로 해당 저장소에 linkedList로 저장할경우,, key의 수를 m , 저장소 길이가 n => 1개의 hash당 들어있는 key의 갯수 
        -특징
            -객체들을 순서없이 저장하고 동일한 객체를 중복 저장하지 않는다
            -중복되지 않는 값을 등록할때 용이
            -순서없이 저장되는것 주의
            -null 허용
    -TreeSet
        -시간복잡도
            -add : O(log n)
            -contains : O(log n)
        -특징
            -오름차순으로 정렬되어있음!
            -tree 구조니깐 데이터를 추가하거나 삭제할때 공간 찾는부분에 있어서 log n 의 시간이 소요

    ***
    -LinkedList
        -시간복잡도
            -add             : O(1) => 맨 마지막 노드와 연결..
            -remove          : O(1) => O(N) 인듯함.. 노드가 하나도 없으면 O(1)이겠지만, 노드간에 연결로 된 구조이므로 데이터를 삽입하거나 삭제할때 해당 노드를 찾아야하므로.. O(N).. 그래도 arrayList보다 빠른것은 arrayList와 같이 변동된 사항을 다시 복사하지않으므로..?
            -get             : O(n) => java1.8에서는 그래도 반으로 나눠서 찾기 시작하네.. idx 받으면 반으로 나눳을때 적은수면 앞에노드부터,, 반으로 나눴을때 높은수면 뒤 노드부터 가져옴..
            -Contains        : O(n) => java1.8에서 첫번재 노드부터 쭈욱 찾기시작..
        -특징
            -데이터를 저장하는 각 노드가 이전노드와 다음 노드의 상태만 알고 있음
            -데이터 추가/삭제시 빠름
            -데이터 검색시 처음부터 노드를 순화해야되기 때문에 느림
    
    =>삽입삭제 많다? => LinkedList
    =>검색이 많다? => ArrayList
    참고 : https://woovictory.github.io/2018/12/27/DataStructure-Diff-of-Array-LinkedList/
        https://www.grepiu.com/post/9


    -tree구조에서 log N의 시간복잡도가 나오는이유?
        =>이진트리를 이용해서 M개의 값들중 원하는값을 찾게되면, 루트 노드에서 다음 자식 노드로 넘어갈수록 1/2 씩 줄어들게된다.. 즉, M/2 -> M/4 -> M/8... 이렇게 되기 때무에 검색하는 자료의 수가 2^n이면 이진트리를 사용할경우 log_2(2^n) 이기때문에 n번의 탐색이 된다. 시간복잡도는 그래서 log_2(n)이 된다(지금 여기 n은 그냥 통상적으로 표현할때의 n)
        => 결론은 자식 노드의 수가 m개인 트리로 N개의 자료에서 원하는 값을 탐색하는 알고리즘의 시간복잡도는 log_m(N)이 된다!


    -arrayList vs HashSet
        =>검색하는부분에 있어서는 HashSet이 압도적으로 빠름..
        =>그러나 메모리 사용에 있어서는 arrayList가 약 5.5배 절약됨
        =>빠른만큼 메모리를 많이 사용함!

    -Hash 관련 정리
        -key : 고유한 값이하며, hash함수의 input이 됨,, 다양한 길이의 값이 될수 있음.. 이 상태로 최종 저장소에 저장이 되면 다양한 길이 만큼의 저장소를 구성해 두어야하기때문에 해시 함수로 값을 바꾸어 저장이 되어야 공간의 효율성을 추구할수있다..
        -hash함수 : 키를 hash로 바꿔주는 역할을 한다.. 다양한 길이를 가지고 있는 key를 일정한 길이를 가지는 hash로 변경하여 저장소를 효율적으로 운영할수있도록 도와줌.. 다만, 서로다른 키가 같은 해시가 되는 경우를 해시 충돌이라고 하는데, 해시충돌을 일으키는 확률을 줄이거나, 해시충돌이 최대한 고루 퍼지도록 해야한다..
        -hash : 해시함수의 결과물이며, 저장소(bucket, slot)에서 값과 매칭되어 저장..
        -값 : 저장소에 최종적으로 저장되는 값으로 키와 매칭되어 저장,삭제,검색,접근이 가능해야한다..

        -단점
            1)순서가 있는 배열에는 어울리지 않는다.
                - 상하관계가 있거나, 순서가 중요한 데이터의 경우 Hash Table은 어울리지 않다. 순서와 상관없이 key만을 가지고 hash를 찾아 저장하기 때문이다.
            2)공간 효율성이 떨어진다.
                - 데이터가 저장되기 전에 미리 저장공간을 확보해 놓아야 한다. 공간이 부족하거나 아예 채워지지 않은 경우가 생길 가능성이 있다.
            3)Hash Function의 의존도가 높다.
                - 평균 데이터 처리의 시간복잡도는 O(1)이지만, 이는 해시 함수의 연산을 고려하지 않는 결과이다. 해시함수가 매우 복잡하다면 해시테이블의 모든 연산의 시간 효율성은 증가할 것이다.

        hash관련 정리글 : https://velog.io/@cyranocoding/Hash-Hashing-Hash-Table%ED%95%B4%EC%8B%9C-%ED%95%B4%EC%8B%B1-%ED%95%B4%EC%8B%9C%ED%85%8C%EC%9D%B4%EB%B8%94-%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0%EC%9D%98-%EC%9D%B4%ED%95%B4-6ijyonph6o
    ***

-성능
-검색에는 뭐가 제일 빠른가?
-hashmap vs hashset
    => 비교대상이 아님.. map과 set.. ㅡㅡ
-hashmap vs treemap



시간복잡도 내용 정리 : https://joshuajangblog.wordpress.com/2016/09/21/time_complexity_big_o_in_easy_explanation/
그림으로 컬렉션 정리 잘되어잇음 : https://hwan1001.tistory.com/m/10

collection 시간복잡도 정리(좀 이상한부분도 있는듯..?) : https://soft.plusblog.co.kr/74

hashMap관련한 수준높은? 설명.. : https://d2.naver.com/helloworld/831311


collection관련 인터뷰 정리 : https://starplatina.tistory.com/entry/%EC%9E%90%EB%B0%94-%EC%BB%AC%EB%A0%89%EC%85%98-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC-%EC%9D%B8%ED%84%B0%EB%B7%B0-%EC%A7%88%EB%AC%B8-40%EA%B0%9C

################################################################################################################################################################
2. thread dump 하는이유?
-스레드 상태 알수있음.. 데드락상태인지(block이 두개) runnable상태인지, wait상태인지
    *스레드상태 : NEW(Thread가 생성된 상태, 아직 start()되지않음), runnable(run 가능한상태.. 스케줄러에 올라와서 run할 준비..), waiting(스레드 잠시 대기 - ex. wait, join..), timed_waiting(시간 정해준 wait, sleep ..), blocked(sync처리와같은부분으로 인해 실행못하고 대기중인것), running(실행중), TERMINAGED(실행마침)


-뭔가 프로세스가 급격히 느려질떄..(어딘가에서 먹통일때..) 어디서 문제 있는지 찾기좋음(스레드 상태보고..)
    -Runnable들중에 뭔가 느리게 실행되고있는게 있을수 있겠지..
-데드락이 나타날때..
    -blocked 되어있는것이 두개이고 어떤 스레드를 기다리고있는지 확인하면 교착상태를 확인가능!
예제로 설명 굿 : https://brunch.co.kr/@springboot/126


-모든 시스템에 응답이 없을 때
-사용자 수가 많지 않은데 CPU사용량이 높을때
-특정어플리케이션 수행 시 응답이 없을때
-간헐적으로 응답이 느릴때
-서비스 실행시간이 길어질수록 응답시간이나 cpu 사용량이 늘어날떄 등등
출처: https://sjh836.tistory.com/151 [빨간색코딩]



*cpu 많이 점유하는거 찾아서 스레드 덤프하기
1) cpu 많이 점유하는 PID 찾기
    $ ps -mo pid,lwp,stime,time,cpu -C java
2) 찾은 PID로 스레드 덤프
3) 1)에서 검색해서 찾은 lwp값을 16진수로 변경하여 NID 검색(여기가 cpu 많이 먹는곳..)
설명 매우 굿 : https://d2.naver.com/helloworld/10963

################################################################################################################################################################


3. 304 error





################################################################################################################################################################

4. 소켓끊어질때 상태변화 o
   client   <->     server
   close




################################################################################################################################################################
5. 람다 functional interface 종류
-Functions
-Suppliers
-Consumers
-Predicates
-Operators


################################################################################################################################################################
6. clustered-index vs non-clustered-index
https://lng1982.tistory.com/144
https://mongyang.tistory.com/75
https://estenpark.tistory.com/384

-인덱스 생성시 발생되는 특징
    -검색속도향상
        -시스템 부하를 줄여, 시스템 전체 성능향상에 기여
    -인덱스를 위한 추가 공간 필요
    -생성에 시간이 소요될 수 있음
    -Insert, update, delete가 자주 발생한다면 성능이 많이 하락할수 있음..

-종류
    -clustered-index
        -테이블당 한개만 생성 가능(PK)
        -행 데이터를 인덱스로 지정한 열에 맞춰서 자동 "정렬"한다..
        -영어사전처럼 책의 내용 자체가 순서대로 정렬이 되어있어, 인덱스 자체가 책의 내용과 같음..

    -non-clustered-index
        -테이블당 여러개 생성가능
        -찾아보기가있는 책과 같음,, 그냥 일반책..

-인덱스 생성
    -인덱스는 열 단위로 생성
    -하나의 열에 인덱스를 생성할수있고, 여러 열에 하나의 인덱스를 생성 할 수 있다..
    -PK지정시 자동으로 클러스터형 인덱스 생성..
    -제약 조건 없이 테이블 생성시에 인덱스를 만들 수 없으며, 인덱스가 자동 생성되기 위한 열의 제약 조건은 PK또는 UNIQUE 뿐이다

-클러스터형 인덱스 생성 및 구조
    -클러스터형 인덱스를 구성하기 위해서 행 데이터를 해당 열로 정렬한 후에, 루트 페이지를 만들게 된다..
    -클러스터형 인덱스는 루트페이지와 리프페이지로 구성되며, 리프 페이지는 데이터 그 자체이다.
    -클러스터형 인덱스는 검색속도가 비클러스터형 인덱스 보다 더 빠르다..

-비클러스터형 인덱스 생성 및 구조
    -데이터 페이지를 건들지않고, 별도의 장소에 인덱스 페이지를 생성
    -인덱스 페이지의 리프메세지에 인덱스로 구성한 열을 정렬한 후 위치포인터(데이터 페이지와 연결)를 생성

-특징
    -클러스터형 인덱스
        -인덱스를 생성할때 데이터 페이지 전체를 다시 정렬
        -이미 대용량의 데이터가 입력된 상태라면, 업무시간에 클러스터형 인덱스를 생성하는 것은 심각한 시스템 부하를 줄 수 있으므로 신중해ㅑㅇ함..
        -클러스터형 인덱스는 인덱스 자체의 리프페이지가 곧 데이터 페이지이다.. 즉, 인덱스 자체에 데이터가 포함
        -넌 클러스터보다 검색빠른데, 데이터의 입력/수정/삭제는 느림
        -물리적으로 디스크에 정렬되어저장(그렇기에 auto increment와 같은걸 쓰는게좋음)
    -넌클러스터형 인덱스
        -넌클러서터형 인덱스를 생성할때는 데이터 페이지는 그냥 둔 상태에서 별도의 페에지에 인덱스를 구성
        -인덱스 자체의 리프 페이지는 데이터가 아니라, 데이터가 위치하는 포인터,, 클러스터형보다 검색속도는 느리지만, 데이터으 입력/수정/삭제는 빠름
        -여러개 생성가능,, 함부로 남용할때 시스템 성능떨어질수있음..

*DB내용들 biztalk study에 옮겨놓기


################################################################################################################################################################

7. webflux

지금 일단 파악한바로는.. Netty를 기반으로 통신하게되니.. 요청이들어오면 url mapping(router) 해주고 비지니스 로직 실행하는식으로 동작하는듯함.. 즉, 라우터의 역할이 특정 핸들러로 연결시켜서 핸들러에서 비지니스로직을 실행하는느낌..


설명굿
=> https://blog.naver.com/PostView.nhn?blogId=spdlqjdudghl&logNo=221589536704&categoryNo=0&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=postView


백프레셔(back pressure) : Publisher 에서 발행하고, Subscriber에서 구독할 때, Publisher 에서 데이터를 Subscriber 로 Push 하는 방식이 아니라, Pull 방식으로 Subscriber 가 Publisher 로 처리할 수 있는 양의 크기만큼 데이터를 요청 함으로써 Subscriber의 장애를 방지하기 위함이다.
즉, 다이나믹 풀 방식의 데이터 요청을 통해서 구독자가 수용할 수 있는 만큼 데이터를 요청하는 방식이다.

스프링5는 Spring Boot 2 부터 도입이 되었으니, Spring Boot 2 의 stack 는 아래와 같다.
    -개발자는 Reactive Stack 를 사용할지, Servlet Stack 를 사용할지 선택을 해야 한다. 두개의 stack 을 동시에 사용할 수 없다.
    이미지 : https://blog.kakaocdn.net/dn/u6sBC/btqCLdDhiTm/lX2HdQpFWbZ1F6MVDIfAz1/img.png

https://hyunsoori.tistory.com/3

webflux 생긴이유에 대해서 설명 잘해줌 : https://heeyeah.github.io/spring/2020-02-29-web-flux/

webflux 다양하게 사용하는 예제 설명 굿 : https://hojak99.tistory.com/453

webflux 사용하여 service 만든 예제 : https://m.blog.naver.com/PostView.nhn?blogId=dg110&logNo=221347127351&proxyReferer=https:%2F%2Fwww.google.com%2F